{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "파인튜닝을 위한 코드이다. 이미 존재하는 모델에 추가 데이터를 투입하여 파라미터를 업데이트를 위한 코드이다."
      ],
      "metadata": {
        "id": "_63KiWDAJRnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. 구글 드라이브를 코랩에 연결한다.**\n",
        "> 이는 추후 모델을 불러오고, 학습할 데이터를 불러오기 위해 필요한 과정이다. \\\n",
        " 따라서 이 코드를 실행하기 전에, 구글 드라이브에 모델과 토크나이저, 전처리된 데이터를 업로드 해야 한다."
      ],
      "metadata": {
        "id": "WF-eA4rJkdep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkt_udVIoCJC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. 파인튜닝을 위해 필요한 라이브러리를 불러온다.**"
      ],
      "metadata": {
        "id": "2VdfRFOzjL4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-6NGKQfC3WI"
      },
      "outputs": [],
      "source": [
        "!pip install transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "969yCCDOC3WS"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF7__pf1C3WW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ElectraTokenizerFast, ElectraConfig, ElectraForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXDLb7DVC3WZ"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. 파인튜닝을 위한 데이터셋을 불러온다.**\n",
        "> ***데이터의 경로 입력/수정 필수!***"
      ],
      "metadata": {
        "id": "QpdMQhznVGCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvPgbiYHC3Wc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/2022_lesik_workspace/lesik/data/total+yejib_train.tsv', sep = '\\t', keep_default_na=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "태그는 최근 모델과 동일해야 되므로 변경해서는 안된다."
      ],
      "metadata": {
        "id": "vUBdq-4wgmjn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_CDSb4AZ0C5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Split labels based on whitespace and turn them into a list\n",
        "arr_labels = set()\n",
        "for lb in df.label:\n",
        "    lb = lb.split()\n",
        "    for ll in lb:\n",
        "        if ll not in arr_labels:\n",
        "            arr_labels.add(ll)\n",
        "\n",
        "#말뭉치 데이터에 포함된 총 태그\n",
        "unique_labels = {'OGG_EDUCATION', 'MT_ELEMENT', 'AFW_OTHER_PRODUCTS', 'MT_ROCK', 'TI_OTHERS', 'PS_NAME', 'CV_BUILDING_TYPE', 'AM_REPTILIA', 'OGG_FOOD', 'AF_MUSICAL_INSTRUMENT', 'AF_BUILDING', 'AFA_MUSIC', 'CV_SPORTS_INST', 'QT_ORDER', 'TM_COLOR', 'LCG_MOUNTAIN', 'QT_MAN_COUNT', 'PS_CHARACTER', 'AM_OTHERS', 'OGG_LIBRARY', 'TMM_DISEASE', 'OGG_MEDICINE', 'LCG_ISLAND', 'TI_MINUTE', 'MT_CHEMICAL', 'TM_CELL_TISSUE_ORGAN', 'QT_OTHERS', 'CV_TRIBE', 'QT_TEMPERATURE', 'PT_FLOWER', 'OGG_POLITICS', 'DT_WEEK', 'FD_ART', 'AM_AMPHIBIA', 'FD_MEDICINE', 'AF_CULTURAL_ASSET', 'AF_TRANSPORT', 'EV_SPORTS', 'LCG_CONTINENT', 'PT_TREE', 'TMI_SERVICE', 'AM_MAMMALIA', 'TM_SPORTS', 'CV_INGREDIENT', 'OGG_HOTEL', 'QT_PHONE', 'CV_LANGUAGE', 'CV_FUNDS', 'CV_CURRENCY', 'FD_OTHERS', 'LCG_RIVER', 'LCP_CAPITALCITY', 'LC_OTHERS', 'QT_SIZE', 'TM_CLIMATE', 'TM_SHAPE', 'CV_POLICY', 'EV_ACTIVITY', 'TR_ART', 'QT_ADDRESS', 'OGG_RELIGION', 'CV_POSITION', 'FD_HUMANITIES', 'CV_CULTURE', 'QT_SPORTS', 'QT_ALBUM', 'CV_ART', 'CV_FOOD', 'CV_LAW', 'OGG_MILITARY', 'DT_DAY', 'FD_SOCIAL_SCIENCE', 'LCP_PROVINCE', 'CV_CLOTHING', 'TI_HOUR', 'DT_DYNASTY', 'DT_SEASON', 'FD_SCIENCE', 'TMI_HW', 'OGG_SPORTS', 'TR_OTHERS', 'TM_DIRECTION', 'TMI_SITE', 'QT_LENGTH', 'MT_METAL', 'LCG_OCEAN', 'DT_OTHERS', 'LCP_COUNTY', 'TMIG_GENRE', 'OGG_ECONOMY', 'TMI_SW', 'CV_SPORTS_POSITION', 'AFA_DOCUMENT', 'PT_OTHERS', 'AFA_ART_CRAFT', 'EV_OTHERS', 'TMI_EMAIL', 'QT_PRICE', 'EV_FESTIVAL', 'TI_SECOND', 'CV_TAX', 'O', 'QT_VOLUME', 'AF_WEAPON', 'LCG_BAY', 'OGG_SCIENCE', 'PT_FRUIT', 'CV_OCCUPATION', 'QT_CHANNEL', 'OGG_ART', 'AM_INSECT', 'CV_FOOD_STYLE', 'QT_PERCENTAGE', 'OGG_LAW', 'TR_SCIENCE', 'CV_RELATION', 'AM_PART', 'QT_AGE', 'TMI_MODEL', 'AM_BIRD', 'OGG_OTHERS', 'CV_SPORTS', 'DT_YEAR', 'LCP_COUNTRY', 'AFA_VIDEO', 'DT_GEOAGE', 'TI_DURATION', 'AM_TYPE', 'CV_SEASONING', 'AM_FISH', 'CV_PRIZE', 'PS_PET', 'AFW_SERVICE_PRODUCTS', 'TMI_PROJECT', 'CV_DRINK', 'LC_SPACE', 'LCP_CITY', 'EV_WAR_REVOLUTION', 'AFA_PERFORMANCE', 'QT_SPEED', 'PT_GRASS', 'DT_MONTH', 'PT_PART', 'OGG_MEDIA', 'PT_TYPE', 'TMM_DRUG', 'AF_ROAD', 'DT_DURATION', 'TR_MEDICINE', 'TR_HUMANITIES'}\n",
        "\n",
        "# Map each label into its id representation and vice versa\n",
        "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
        "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
        "\n",
        " #말뭉치에 포함되어 있지 않는 태그들 추가       \n",
        "labels_to_ids['CV_ACT'] = 150\n",
        "ids_to_labels[150] = 'CV_ACT'\n",
        "\n",
        "labels_to_ids['CV_STATE'] = 151\n",
        "ids_to_labels[151] = 'CV_STATE'\n",
        "\n",
        "print(ids_to_labels)\n",
        "print(len(ids_to_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at how can we preprocess the text - Take first example\n",
        "text = df['text'].values.tolist()\n",
        "m_len = 0\n",
        "for t in text:\n",
        "    if m_len < len(t):\n",
        "        m_len = len(t)\n",
        "        \n",
        "example = text[1]\n",
        "\n",
        "print(example)\n",
        "print(m_len)"
      ],
      "metadata": {
        "id": "3IGRA-iG_cjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. 파인튜닝한 최종 모델과 토크나이저를 불러온다.**\n",
        "> ***모델, 토크나이저, epoch 입력/수정 필수!***\n",
        "\n"
      ],
      "metadata": {
        "id": "UOnkOhZZWSi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원하는 모델과 토크나이저를 불러오는 함수이다. \\\n",
        "\"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FIXED_FINAL_EPOCH_\"는 드라이브 내의 경로를 나타내는데, 왼쪽의 폴더 버튼을 눌러서 원하는 데이터의 경로를 확인할 수 있다.\n"
      ],
      "metadata": {
        "id": "bbs9xymmWlp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4IhZVRfAWqn"
      },
      "outputs": [],
      "source": [
        "def load(epoch):\n",
        "    model_directory = '/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FIXED_FINAL_EPOCH_'+ str(epoch) #모델 경로\n",
        "    model = ElectraForTokenClassification.from_pretrained(model_directory, num_labels=len(labels_to_ids))\n",
        "    model.to(device)\n",
        "    \n",
        "    tokenizer_directory = '/content/gdrive/MyDrive/2022_lesik_workspace/lesik/tokenizer/FIXED_FINAL_EPOCH_' +str(epoch) #토크나이저 경로\n",
        "    tokenizer = ElectraTokenizerFast.from_pretrained(tokenizer_directory)\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "argument로 불러오기를 원하는 epoch를 적는다."
      ],
      "metadata": {
        "id": "3JjzYNDANUwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KB4kWc8C3Ws"
      },
      "outputs": [],
      "source": [
        "epoch = 72              #원하는 epoch로 변경\n",
        "model, tokenizer = load(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. 토큰화를 하기 위해 필요한 코드이다.**\n",
        "> ***원하는 epoch로 수정 가능!***"
      ],
      "metadata": {
        "id": "VGZyQqpxWytM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTy4INQtL4_S"
      },
      "source": [
        "epoch 개수는 고정이 아니므로 각 모델에 적절 또는 최적화 되어있는 개수로 변경하면 된다. \\\n",
        "(저희는 말뭉치 제외하고 72로 고정해서 학습) \\\n",
        "학습 중에 중단 되었을 경우, 저장된 epoch부터 이어서 학습 시킬 수 있다. 단, epochs를 저장된 epoch만큼 빼서 변경해줘야한다.\n",
        "> ex.) epoch 72를 목표하였고, epoch 48까지 저장된 후 중단 되었다면 \\\n",
        "72-48 = 24; epochs를 24로 변경해주면 된다. \n",
        "\n",
        "(8.학습 실행 코드 참고)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvnxXpk8C3W2"
      },
      "outputs": [],
      "source": [
        "from transformers import ElectraTokenizerFast\n",
        "\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 72             #원하는 epoch로 변경\n",
        "LEARNING_RATE = 1e-06\n",
        "MAX_GRAD_NORM = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpZ1jCnGC3XC"
      },
      "outputs": [],
      "source": [
        "class ElectraDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: get the sentence and word labels\n",
        "        sentence = self.data.text[index].strip() #문장 하나\n",
        "        word_labels = self.data.label[index].split() # 한 문장의 레이블들을 모아놓은 리스트\n",
        "\n",
        "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
        "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                             return_offsets_mapping=True, \n",
        "                             padding='max_length', \n",
        "                             truncation=True, \n",
        "                             max_length=self.max_len)\n",
        "        valid_token_list = []\n",
        "        \n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "            if mapping[0] == 0 and mapping[1] == 0: #[cls]가 아니면\n",
        "                continue\n",
        "            valid_token_list.append(mapping)\n",
        "        if len(valid_token_list) != len(word_labels): \n",
        "            print(index, len(word_labels), len(valid_token_list), sentence)\n",
        "        \n",
        "        # step 3: create token labels only for first word pieces of each tokenized word\n",
        "        labels = [labels_to_ids[label] for label in word_labels] # 워드 레이블: 문장의 레이블을 모아놓은 리스트\n",
        "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "        \n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        if len(labels) != 0:\n",
        "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "                if mapping[0] == 0 and mapping[1] == 0: # [cls]가 아니면\n",
        "                    continue\n",
        "                tok = tokenizer.convert_ids_to_tokens(encoding['input_ids'][idx]) # 토큰이 저장됨\n",
        "            \n",
        "                # overwrite label\n",
        "                if i == len(labels):\n",
        "                    break\n",
        "                encoded_labels[idx] = labels[i] # 레이블 저장\n",
        "                i += 1           \n",
        "\n",
        "        # step 4: turn everything into PyTorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['label'] = torch.as_tensor(encoded_labels)   \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk3JvViRC3XE",
        "outputId": "01e4d377-9a76-435b-db0a-e091e7b24b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (5393, 2)\n",
            "TRAIN Dataset: (4314, 2)\n",
            "VALIDATION Dataset: (1079, 2)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "train_size = 0.8\n",
        "train_dataset = df.sample(frac=train_size,random_state=200)\n",
        "validation_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape)) # 0.8\n",
        "print(\"VALIDATION Dataset: {}\".format(validation_dataset.shape)) # 0.2\n",
        "\n",
        "training_set = ElectraDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = ElectraDataset(validation_dataset, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Cv53qH97a8P"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 4\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 4\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO7lkEcVC3XL"
      },
      "outputs": [],
      "source": [
        "model.to(device) # cpu / gpu 사용 뭐 할지 선택 (꼭 필요!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knuKPJOiHbiZ"
      },
      "outputs": [],
      "source": [
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"label\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inT7nrGIC3XN",
        "outputId": "cbe2a759-d669-4ef3-968a-c15fb14630f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256, 152])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5oWYyUqC3XO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDMEDa-1C3XQ"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. train, validation 함수를 불러오는 섹션이다.**"
      ],
      "metadata": {
        "id": "0qIdZJqGdIze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train을 위한 함수이다."
      ],
      "metadata": {
        "id": "9mvB0gwtbgS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft-PEsUMC3XR"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['label'].to(device, dtype = torch.long)\n",
        "\n",
        "        output = model(ids, attention_mask=mask, labels=labels)\n",
        "        loss = output[0]\n",
        "        tr_logits = output[1]\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "        # compute training accuracy\n",
        "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        \n",
        "        # only compute accuracy at active labels\n",
        "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
        "        \n",
        "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_labels.extend(labels)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "        \n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
        "    writer.add_scalar('Train/Accuracy', tr_accuracy, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation을 위한 함수이다."
      ],
      "metadata": {
        "id": "_fPKp4y2bmfZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YySwXwipC3XT"
      },
      "outputs": [],
      "source": [
        "def valid(epoch):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['label'].to(device, dtype = torch.long)\n",
        "            \n",
        "            output = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "            loss = output[0]\n",
        "            eval_logits = output[1]\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            \n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        \n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    writer.add_scalar('Validation/Loss', eval_loss, epoch)\n",
        "    writer.add_scalar('Validation/Accuracy', eval_accuracy, epoch)\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7. save 함수를 불러오는 섹션이다.**\n",
        "> ***directory/model/tokenizer 이름 변경은 필수!***"
      ],
      "metadata": {
        "id": "rBdxQnDmowAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 저장을 위한 함수이다."
      ],
      "metadata": {
        "id": "HE0sKIX3Qbv_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3nYYHRqC3XV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def save(epoch):\n",
        "    directory = \"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/model/FTEST_EPOCH_\"+ str(epoch)\n",
        "    \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    model.save_pretrained(directory)\n",
        "\n",
        "    torch.save(model.state_dict(), directory+\"/model.pt\")\n",
        "    directory = \"/content/gdrive/MyDrive/2022_lesik_workspace/lesik/tokenizer/FTEST_EPOCH_\" + str(epoch)\n",
        "    \n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    # save vocabulary of the tokenizer\n",
        "    tokenizer.save_vocabulary(directory)\n",
        "    tokenizer.save_pretrained(directory)\n",
        "    # save the model weights and its configuration file\n",
        "    print('All files saved')\n",
        "    print('This tutorial is completed')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**8. 학습을 실행하는 코드이다.**\n",
        "> ***학습 과정에서 끊겼을 경우, prev_epoch 변경 필수! 그 외는 0으로 실행!***"
      ],
      "metadata": {
        "id": "Khlzc34eeKSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   prev_epoch는 학습을 시작하는 지점을 뜻하는 epoch이다.\n",
        "*   학습하다 끊겼을 경우, 저장 단위의 배수를 계산하여 마지막으로 저장된 epoch로 변경 해주면 된다. \\\n",
        "또한, 토큰화에서도 목표하고자 하는epoch를 저장된 epoch만큼 빼서 변경해줘야 한다.\n",
        "> ex.)epoch가 50에서 중단 되었을 경우, \\\n",
        "epoch 48까지 저장되었기 때문에 prev_epoch는 48로 시작. 토큰화의 epoch는 24로 변경. \\\n",
        "단, 51에서 중단되었을 경우, \\\n",
        "epoch 51이 저장되었다면, prev_epoch는 51부터 시작. 토큰화의 epoch는 21로 변경. \\\n",
        "epoch 51이 저장되지 않았다면,prev_epoch는 48부터 시작. 토큰화의 epoch는 24로 변경.\n",
        "*   epoch는 현재 3의 배수로 저장되고 있으며, 변경이 가능하다."
      ],
      "metadata": {
        "id": "_rRIDj-tiH-S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJbOtD9fYnN1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "prev_epoch = 0          #학습을 시작하는 epoch\n",
        "for epoch in range(prev_epoch + 1, prev_epoch + 1 + EPOCHS):\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    if epoch != 0 and epoch % 3 == 0: #현재 3의 배수로 저장되고 있으며 변경 가능 (3을 변경해주면 됩니다.)\n",
        "        save(epoch)\n",
        "    train(epoch)\n",
        "    labels, predictions = valid(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **(선택) 모델 학습 출력**\n",
        ">*** tensorboard 불러오기***"
      ],
      "metadata": {
        "id": "AgM5-Gz6Q1M_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WP479GGC3XX"
      },
      "outputs": [],
      "source": [
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드들을 실행하면 텐서보드를 작동시켜 그래프를 확인할 수 있다."
      ],
      "metadata": {
        "id": "IXvblDmCQCq9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em2iKkc5u3y3"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs --port=6000"
      ],
      "metadata": {
        "id": "_-y_YCC8QtG9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "PyTorch 1.13 (NGC 22.05/Python 3.8 Conda) on Backend.AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}